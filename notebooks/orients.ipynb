{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db8658-d7ad-405c-a773-7e09ed54adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf8 -*-\n",
    "# !/usr/bin/env python3\n",
    "# Copyright 2025 Volodymyr Pavliukevych\n",
    "# Author Volodymyr Pavliukevych\n",
    "\n",
    "\"\"\"This is a POC representation\n",
    "\"\"\"\n",
    "import os \n",
    "import cv2\n",
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "from itertools import combinations\n",
    "from math import comb\n",
    "import shutil\n",
    "\n",
    "__file__ = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf78d71-06ce-47d1-beb7-2fb07327cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageProcessor:\n",
    "\t\"\"\"\n",
    "\tA class to process images from a dataset, including downloading, unzipping, and feature extraction using SIFT.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, dataset_folder_name:str='dataset', dataset_url:str=None, images_for_process: list = ['.tif']):\n",
    "\t\tself.dataset_folder_name = dataset_folder_name\n",
    "\t\tself.improved_dataset_folder_name = \"improved_dataset\"\n",
    "\t\tself.dataset_url = dataset_url\n",
    "\t\tself.images_for_process = images_for_process\n",
    "\t\tself.images_descriptions = []\n",
    "\n",
    "\t@property\n",
    "\tdef dataset_path(self):\n",
    "\t\treturn os.path.join(os.path.dirname(__file__), self.dataset_folder_name)\n",
    "\n",
    "\t@property\n",
    "\tdef improved_dataset_path(self):\n",
    "\t\treturn os.path.join(os.path.dirname(__file__), self.improved_dataset_folder_name)\n",
    "\t\n",
    "\tdef read_and_prepare_image(self, img_name: str) -> tuple:\n",
    "\t\t\"\"\"\n",
    "\t\tRead and prepare an image for processing.\n",
    "\t\t\"\"\"\n",
    "\t\timg_path = os.path.join(self.dataset_path, img_name)\n",
    "\t\timg = cv2.imread(img_path) #, cv2.IMREAD_UNCHANGED\n",
    "\n",
    "\t\t# Get the original dimensions\n",
    "\t\toriginal_height, original_width = img.shape[:2]\n",
    "\t\t\t\t\n",
    "\t\tscale_factor = 0.50\n",
    "\t\tratio = None\n",
    "\t\tshape = None\n",
    "\t\t# Calculate the scaling factor while maintaining the aspect ratio\n",
    "\t\tif shape is not None:\n",
    "\t\t\tscale_factor = min(img.shape[0] / original_width, img.shape[1] / original_height)\n",
    "\t\tif isinstance(ratio, float) or isinstance(ratio, int):\n",
    "\t\t\tscale_factor = ratio\n",
    "\t\t# Calculate new dimensions\n",
    "\t\tnew_width = int(original_width * scale_factor)\n",
    "\t\tnew_height = int(original_height * scale_factor)\n",
    "\t\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\t\t# Experiment with grayscale\n",
    "\t\tgray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\t\t# gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# gray_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "\t\tgray_img = cv2.resize(gray_img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t# Enhance contrast using CLAHE\n",
    "\t\tclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\t\tenhanced_img = clahe.apply(gray_img)\n",
    "\n",
    "\t\t# Apply Laplacian filter to enhance edges\n",
    "\t\tlaplacian = cv2.Laplacian(enhanced_img, cv2.CV_64F)\n",
    "\t\tedge_enhanced_img = cv2.convertScaleAbs(laplacian)\n",
    "\t\tedge_enhanced_img = cv2.resize(edge_enhanced_img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\t\n",
    "\t\treturn (img, gray_img, edge_enhanced_img)\n",
    "\t\n",
    "\tdef load_dataset(self) -> str:\n",
    "\t\t\"\"\"\n",
    "\t\tLoad the dataset from the specified URL if it doesn't exist locally.\n",
    "\t\t\"\"\"\n",
    "\t\tif os.path.exists(self.dataset_path):\n",
    "\t\t\treturn self.dataset_path\n",
    "\t\t# Download the dataset if it doesn't exist\n",
    "\t\tif not os.path.exists(os.path.join(self.dataset_path, 'dataset.zip')):\n",
    "\t\t\tself.download_dataset()\n",
    "\n",
    "\t\t# Unzip the dataset\n",
    "\t\tself.unzip_dataset()\n",
    "\t\treturn self.dataset_path\n",
    "\n",
    "\tdef download_dataset(self):\n",
    "\t\t\"\"\"\n",
    "\t\tDownload the dataset from the specified URL.\n",
    "\t\t\"\"\"\n",
    "\t\tresponse = requests.get(self.dataset_url, stream=True)\n",
    "\t\ttotal_size = int(response.headers.get('content-length', 0))\n",
    "\t\tblock_size = 1024\n",
    "\t\twith open(os.path.join(os.path.dirname(__file__), 'dataset.zip'), 'wb') as file:\n",
    "\t\t\tfor data in tqdm(response.iter_content(block_size), total=total_size, unit='KB', unit_scale=True):\n",
    "\t\t\t\tfile.write(data)\n",
    "\t\n",
    "\tdef unzip_dataset(self):\n",
    "\t\twith zipfile.ZipFile(os.path.join(self.dataset_path, 'dataset.zip'), 'r') as zip_ref:\n",
    "\t\t\tzip_ref.extractall(self.dataset_path)\n",
    "\n",
    "\tdef process_images(self):\n",
    "\t\t\"\"\"\n",
    "\t\tProcess images in the dataset to extract SIFT features.\n",
    "\t\t\"\"\"\n",
    "\t\tsift = cv2.SIFT_create(contrastThreshold=0.01)\n",
    "\n",
    "\t\t# Process the images\n",
    "\t\tfor _, _, files in os.walk(self.dataset_path):\n",
    "\t\t\tindex = 0\n",
    "\t\t\tfor file_path in tqdm(files, desc=\"Processing images\", unit=\"file\"):\n",
    "\t\t\t\tindex += 1\n",
    "\t\t\t\tif index > 25:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tfile_type = os.path.splitext(file_path)[1]\n",
    "\t\t\t\tif file_type not in self.images_for_process:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t_, img, _ = self.read_and_prepare_image(file_path)\n",
    "\t\t\t\tif img is None:\n",
    "\t\t\t\t\tprint(f\"Failed to load image at path: {file_path}\")\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tkeypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\t\t\t\tif descriptors is None:\n",
    "\t\t\t\t\tprint(f\"Failed to compute descriptors for image at path: {file_path}\")\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.images_descriptions.append({\n",
    "\t\t\t\t\t# 'image': img,\n",
    "\t\t\t\t\t'path': os.path.join(self.dataset_path, file_path),\n",
    "\t\t\t\t\t'image_name': file_path,\n",
    "\t\t\t\t\t'keypoints': keypoints,\n",
    "\t\t\t\t\t'descriptors': descriptors\n",
    "\t\t\t\t})\n",
    "\n",
    "\tdef compare_sift_features(self, ratio_thresh=0.75, match_thresh=100):\n",
    "\t\t\"\"\"\n",
    "\t\tCompare SIFT features of images in the dataset and find similar pairs.\n",
    "\t\t\"\"\"\n",
    "\t\tbf = cv2.BFMatcher()\n",
    "\t\tsimilar_pairs = []\n",
    "\t\tzones = []\n",
    "\n",
    "\t\ttotal_pairs = comb(len(self.images_descriptions), 2)\n",
    "\t\tfor img1, img2 in tqdm(combinations(self.images_descriptions, 2), desc=\"Comparing images\", unit=\"pair\", total=total_pairs):\n",
    "\t\t\t# Compare the descriptors of the two images\n",
    "\t\t\tdes1 = img1['descriptors']\n",
    "\t\t\tdes2 = img2['descriptors']\n",
    "\n",
    "\t\t\tkps1 = img1['keypoints']\n",
    "\t\t\tkps2 = img2['keypoints']\n",
    "\n",
    "\t\t\tmatches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "\t\t\t# Lowe's ratio test\n",
    "\t\t\tgood_matches = [m for m, n in matches if m.distance < ratio_thresh * n.distance]\n",
    "\t\t\tif False:\n",
    "\t\t\t\tmatched_kps = [kps2[m.trainIdx] for m in good_matches]\n",
    "\t\t\t\t\n",
    "\t\t\t\timage_1 = cv2.drawKeypoints(img1['image'], matched_kps, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\t\t\t\timage_2 = cv2.drawKeypoints(img2['image'], matched_kps, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\t\t\t\t\n",
    "\t\t\t\tcv2.imwrite(f\"{img1['path']}_keypoints.png\", image_1)\n",
    "\t\t\t\tcv2.imwrite(f\"{img2['path']}_keypoints.png\", image_2)\n",
    "\n",
    "\t\t\tif len(good_matches) >= match_thresh:\n",
    "\t\t\t\tfound_corelated_zone = False\n",
    "\t\t\t\tfor zone in zones:\n",
    "\t\t\t\t\textended_zone = zone.copy()\n",
    "\t\t\t\t\tif img1['image_name'] in zone or img2['image_name'] in zone:\n",
    "\t\t\t\t\t\tfound_corelated_zone = True\n",
    "\t\t\t\t\t\tif img1['image_name'] not in zone:\n",
    "\t\t\t\t\t\t\textended_zone.add(img1['image_name'])\n",
    "\t\t\t\t\t\tif img2['image_name'] not in zone:\n",
    "\t\t\t\t\t\t\textended_zone.add(img2['image_name'])\n",
    "\t\t\t\t\t\tzones.remove(zone)\n",
    "\t\t\t\t\t\tzones.append(extended_zone)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\tif found_corelated_zone == False:\n",
    "\t\t\t\t\tzone = set()\n",
    "\t\t\t\t\tzone.add(img1['image_name'])\n",
    "\t\t\t\t\tzone.add(img2['image_name'])\n",
    "\t\t\t\t\tzones.append(zone)\n",
    "\t\t\t\t\n",
    "\t\t\t\tsimilar_pairs.append((img1['image_name'], img2['image_name'], len(good_matches)))\n",
    "\t\t\n",
    "\t\t# Save non paired images\n",
    "\t\tfor image in tqdm(self.images_descriptions):\n",
    "\t\t\timage_name = image['image_name']\n",
    "\t\t\tfound_corelated_zone = False\n",
    "\t\t\tfor zone in zones:\n",
    "\t\t\t\tif image_name in zone:\n",
    "\t\t\t\t\tfound_corelated_zone = True\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\tif found_corelated_zone == False:\n",
    "\t\t\t\tzone = set()\n",
    "\t\t\t\tzone.add(image_name)\n",
    "\t\t\t\tzones.append(zone)\n",
    "\n",
    "\t\t# merge similar zones\n",
    "\t\tfor i in range(len(zones)):\n",
    "\t\t\tfor j in range(i + 1, len(zones)):\n",
    "\t\t\t\tif zones[i].intersection(zones[j]):\n",
    "\t\t\t\t\tprint(f\"Zones {i} and {j} are similar: {zones[i]} and {zones[j]}\")\n",
    "\t\t\t\t\tzones[i] = zones[i].union(zones[j])\n",
    "\t\t\t\t\tzones.pop(j)\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\n",
    "\t\tif os.path.exists(self.improved_dataset_path) == False:\n",
    "\t\t\tos.mkdir(self.improved_dataset_path)\n",
    "\t\t\t\n",
    "\t\tfor zone_index, zone in enumerate(zones):\n",
    "\t\t\tprint(f\"Zone {zone_index}: {zone}\")\n",
    "\t\t\tfor photo_index, image_name in enumerate(zone):\n",
    "\t\t\t\tsrc_image_path = os.path.join(self.dataset_path, image_name)\n",
    "\t\t\t\tdst_image_path = os.path.join(self.improved_dataset_path, f\"{zone_index}_{photo_index}_{image_name}.tif\", )\n",
    "\t\t\t\tshutil.copy(src_image_path, dst_image_path)\n",
    "\n",
    "\t\treturn similar_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da56068-c3e7-466c-9400-a425955a1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://orients-ai-artefacts.s3.eu-north-1.amazonaws.com/selection-tasks/landc02/dataset.zip\"\n",
    "image_processor = ImageProcessor(dataset_url=dataset_url)\n",
    "\n",
    "# Load the dataset\n",
    "_ = image_processor.load_dataset()\n",
    "image_processor.process_images()\n",
    "similar_pairs = image_processor.compare_sift_features(ratio_thresh=0.75)\n",
    "print(\"Similar pairs of images:\")\n",
    "for img1, img2, num_matches in similar_pairs:\n",
    "\tprint(f\"Image 1: {img1}, Image 2: {img2}, Matches: {num_matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ebd1d-e1d4-4687-a482-86dd13ec5445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
