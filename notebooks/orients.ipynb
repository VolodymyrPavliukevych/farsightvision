{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46db8658-d7ad-405c-a773-7e09ed54adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf8 -*-\n",
    "# !/usr/bin/env python3\n",
    "# Copyright 2025 Volodymyr Pavliukevych\n",
    "# Author Volodymyr Pavliukevych\n",
    "\n",
    "\"\"\"This is a POC representation\n",
    "\"\"\"\n",
    "import os \n",
    "import cv2\n",
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "from itertools import combinations\n",
    "from math import comb\n",
    "import shutil\n",
    "\n",
    "__file__ = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf78d71-06ce-47d1-beb7-2fb07327cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageProcessor:\n",
    "\t\"\"\"\n",
    "\tA class to process images from a dataset, including downloading, unzipping, and feature extraction using SIFT.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, dataset_folder_name:str='dataset', dataset_url:str=None, images_for_process: list = ['.tif']):\n",
    "\t\tself.dataset_folder_name = dataset_folder_name\n",
    "\t\tself.improved_dataset_folder_name = \"improved_dataset\"\n",
    "\t\tself.dataset_url = dataset_url\n",
    "\t\tself.images_for_process = images_for_process\n",
    "\t\tself.images_descriptions = []\n",
    "\n",
    "\t@property\n",
    "\tdef dataset_path(self):\n",
    "\t\treturn os.path.join(os.path.dirname(__file__), self.dataset_folder_name)\n",
    "\n",
    "\t@property\n",
    "\tdef improved_dataset_path(self):\n",
    "\t\treturn os.path.join(os.path.dirname(__file__), self.improved_dataset_folder_name)\n",
    "\t\n",
    "\tdef read_and_prepare_image(self, img_name: str) -> tuple:\n",
    "\t\t\"\"\"\n",
    "\t\tRead and prepare an image for processing.\n",
    "\t\t\"\"\"\n",
    "\t\timg_path = os.path.join(self.dataset_path, img_name)\n",
    "\t\timg = cv2.imread(img_path) #, cv2.IMREAD_UNCHANGED\n",
    "\n",
    "\t\t# Get the original dimensions\n",
    "\t\toriginal_height, original_width = img.shape[:2]\n",
    "\t\t\t\t\n",
    "\t\tscale_factor = 0.50\n",
    "\t\tratio = None\n",
    "\t\tshape = None\n",
    "\t\t# Calculate the scaling factor while maintaining the aspect ratio\n",
    "\t\tif shape is not None:\n",
    "\t\t\tscale_factor = min(img.shape[0] / original_width, img.shape[1] / original_height)\n",
    "\t\tif isinstance(ratio, float) or isinstance(ratio, int):\n",
    "\t\t\tscale_factor = ratio\n",
    "\t\t# Calculate new dimensions\n",
    "\t\tnew_width = int(original_width * scale_factor)\n",
    "\t\tnew_height = int(original_height * scale_factor)\n",
    "\t\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\t\t# Experiment with grayscale\n",
    "\t\tgray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\t\t# gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# gray_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "\t\tgray_img = cv2.resize(gray_img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t# Enhance contrast using CLAHE\n",
    "\t\tclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\t\tenhanced_img = clahe.apply(gray_img)\n",
    "\n",
    "\t\t# Apply Laplacian filter to enhance edges\n",
    "\t\tlaplacian = cv2.Laplacian(enhanced_img, cv2.CV_64F)\n",
    "\t\tedge_enhanced_img = cv2.convertScaleAbs(laplacian)\n",
    "\t\tedge_enhanced_img = cv2.resize(edge_enhanced_img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\t\n",
    "\t\treturn (img, gray_img, edge_enhanced_img)\n",
    "\t\n",
    "\tdef load_dataset(self) -> str:\n",
    "\t\t\"\"\"\n",
    "\t\tLoad the dataset from the specified URL if it doesn't exist locally.\n",
    "\t\t\"\"\"\n",
    "\t\tif os.path.exists(self.dataset_path):\n",
    "\t\t\treturn self.dataset_path\n",
    "\t\t# Download the dataset if it doesn't exist\n",
    "\t\tif not os.path.exists(os.path.join(self.dataset_path, 'dataset.zip')):\n",
    "\t\t\tself.download_dataset()\n",
    "\n",
    "\t\t# Unzip the dataset\n",
    "\t\tself.unzip_dataset()\n",
    "\t\treturn self.dataset_path\n",
    "\n",
    "\tdef download_dataset(self):\n",
    "\t\t\"\"\"\n",
    "\t\tDownload the dataset from the specified URL.\n",
    "\t\t\"\"\"\n",
    "\t\tresponse = requests.get(self.dataset_url, stream=True)\n",
    "\t\ttotal_size = int(response.headers.get('content-length', 0))\n",
    "\t\tblock_size = 1024\n",
    "\t\twith open(os.path.join(os.path.dirname(__file__), 'dataset.zip'), 'wb') as file:\n",
    "\t\t\tfor data in tqdm(response.iter_content(block_size), total=total_size, unit='KB', unit_scale=True):\n",
    "\t\t\t\tfile.write(data)\n",
    "\t\n",
    "\tdef unzip_dataset(self):\n",
    "\t\twith zipfile.ZipFile(os.path.join(self.dataset_path, 'dataset.zip'), 'r') as zip_ref:\n",
    "\t\t\tzip_ref.extractall(self.dataset_path)\n",
    "\n",
    "\tdef process_images(self):\n",
    "\t\t\"\"\"\n",
    "\t\tProcess images in the dataset to extract SIFT features.\n",
    "\t\t\"\"\"\n",
    "\t\tsift = cv2.SIFT_create(contrastThreshold=0.01)\n",
    "\n",
    "\t\t# Process the images\n",
    "\t\tfor _, _, files in os.walk(self.dataset_path):\n",
    "\t\t\tindex = 0\n",
    "\t\t\tfor file_path in tqdm(files, desc=\"Processing images\", unit=\"file\"):\n",
    "\t\t\t\tindex += 1\n",
    "\t\t\t\tif index > 25:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tfile_type = os.path.splitext(file_path)[1]\n",
    "\t\t\t\tif file_type not in self.images_for_process:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t_, img, _ = self.read_and_prepare_image(file_path)\n",
    "\t\t\t\tif img is None:\n",
    "\t\t\t\t\tprint(f\"Failed to load image at path: {file_path}\")\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tkeypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\t\t\t\tif descriptors is None:\n",
    "\t\t\t\t\tprint(f\"Failed to compute descriptors for image at path: {file_path}\")\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.images_descriptions.append({\n",
    "\t\t\t\t\t# 'image': img,\n",
    "\t\t\t\t\t'path': os.path.join(self.dataset_path, file_path),\n",
    "\t\t\t\t\t'image_name': file_path,\n",
    "\t\t\t\t\t'keypoints': keypoints,\n",
    "\t\t\t\t\t'descriptors': descriptors\n",
    "\t\t\t\t})\n",
    "\n",
    "\tdef compare_sift_features(self, ratio_thresh=0.75, match_thresh=100):\n",
    "\t\t\"\"\"\n",
    "\t\tCompare SIFT features of images in the dataset and find similar pairs.\n",
    "\t\t\"\"\"\n",
    "\t\tbf = cv2.BFMatcher()\n",
    "\t\tsimilar_pairs = []\n",
    "\t\tzones = []\n",
    "\n",
    "\t\ttotal_pairs = comb(len(self.images_descriptions), 2)\n",
    "\t\tfor img1, img2 in tqdm(combinations(self.images_descriptions, 2), desc=\"Comparing images\", unit=\"pair\", total=total_pairs):\n",
    "\t\t\t# Compare the descriptors of the two images\n",
    "\t\t\tdes1 = img1['descriptors']\n",
    "\t\t\tdes2 = img2['descriptors']\n",
    "\n",
    "\t\t\tkps1 = img1['keypoints']\n",
    "\t\t\tkps2 = img2['keypoints']\n",
    "\n",
    "\t\t\tmatches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "\t\t\t# Lowe's ratio test\n",
    "\t\t\tgood_matches = [m for m, n in matches if m.distance < ratio_thresh * n.distance]\n",
    "\t\t\tif False:\n",
    "\t\t\t\tmatched_kps = [kps2[m.trainIdx] for m in good_matches]\n",
    "\t\t\t\t\n",
    "\t\t\t\timage_1 = cv2.drawKeypoints(img1['image'], matched_kps, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\t\t\t\timage_2 = cv2.drawKeypoints(img2['image'], matched_kps, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\t\t\t\t\n",
    "\t\t\t\tcv2.imwrite(f\"{img1['path']}_keypoints.png\", image_1)\n",
    "\t\t\t\tcv2.imwrite(f\"{img2['path']}_keypoints.png\", image_2)\n",
    "\n",
    "\t\t\tif len(good_matches) >= match_thresh:\n",
    "\t\t\t\tfound_corelated_zone = False\n",
    "\t\t\t\tfor zone in zones:\n",
    "\t\t\t\t\textended_zone = zone.copy()\n",
    "\t\t\t\t\tif img1['image_name'] in zone or img2['image_name'] in zone:\n",
    "\t\t\t\t\t\tfound_corelated_zone = True\n",
    "\t\t\t\t\t\tif img1['image_name'] not in zone:\n",
    "\t\t\t\t\t\t\textended_zone.add(img1['image_name'])\n",
    "\t\t\t\t\t\tif img2['image_name'] not in zone:\n",
    "\t\t\t\t\t\t\textended_zone.add(img2['image_name'])\n",
    "\t\t\t\t\t\tzones.remove(zone)\n",
    "\t\t\t\t\t\tzones.append(extended_zone)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\tif found_corelated_zone == False:\n",
    "\t\t\t\t\tzone = set()\n",
    "\t\t\t\t\tzone.add(img1['image_name'])\n",
    "\t\t\t\t\tzone.add(img2['image_name'])\n",
    "\t\t\t\t\tzones.append(zone)\n",
    "\t\t\t\t\n",
    "\t\t\t\tsimilar_pairs.append((img1['image_name'], img2['image_name'], len(good_matches)))\n",
    "\t\t\n",
    "\t\t# Save non paired images\n",
    "\t\tfor image in tqdm(self.images_descriptions):\n",
    "\t\t\timage_name = image['image_name']\n",
    "\t\t\tfound_corelated_zone = False\n",
    "\t\t\tfor zone in zones:\n",
    "\t\t\t\tif image_name in zone:\n",
    "\t\t\t\t\tfound_corelated_zone = True\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\tif found_corelated_zone == False:\n",
    "\t\t\t\tzone = set()\n",
    "\t\t\t\tzone.add(image_name)\n",
    "\t\t\t\tzones.append(zone)\n",
    "\n",
    "\t\t# merge similar zones\n",
    "\t\tfor i in range(len(zones)):\n",
    "\t\t\tfor j in range(i + 1, len(zones)):\n",
    "\t\t\t\tif zones[i].intersection(zones[j]):\n",
    "\t\t\t\t\tprint(f\"Zones {i} and {j} are similar: {zones[i]} and {zones[j]}\")\n",
    "\t\t\t\t\tzones[i] = zones[i].union(zones[j])\n",
    "\t\t\t\t\tzones.pop(j)\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\n",
    "\t\tif os.path.exists(self.improved_dataset_path) == False:\n",
    "\t\t\tos.mkdir(self.improved_dataset_path)\n",
    "\t\t\t\n",
    "\t\tfor zone_index, zone in enumerate(zones):\n",
    "\t\t\tprint(f\"Zone {zone_index}: {zone}\")\n",
    "\t\t\tfor photo_index, image_name in enumerate(zone):\n",
    "\t\t\t\tsrc_image_path = os.path.join(self.dataset_path, image_name)\n",
    "\t\t\t\tdst_image_path = os.path.join(self.improved_dataset_path, f\"{zone_index}_{photo_index}_{image_name}.tif\", )\n",
    "\t\t\t\tshutil.copy(src_image_path, dst_image_path)\n",
    "\n",
    "\t\treturn similar_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da56068-c3e7-466c-9400-a425955a1185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                               | 140k/1.25G [00:36<91:10:33, 3.81kKB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m image_processor \u001b[38;5;241m=\u001b[39m ImageProcessor(dataset_url\u001b[38;5;241m=\u001b[39mdataset_url)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mimage_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m image_processor\u001b[38;5;241m.\u001b[39mprocess_images()\n\u001b[1;32m      7\u001b[0m similar_pairs \u001b[38;5;241m=\u001b[39m image_processor\u001b[38;5;241m.\u001b[39mcompare_sift_features(ratio_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m, in \u001b[0;36mImageProcessor.load_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Download the dataset if it doesn't exist\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m---> 69\u001b[0m \t\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Unzip the dataset\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munzip_dataset()\n",
      "Cell \u001b[0;32mIn[5], line 83\u001b[0m, in \u001b[0;36mImageProcessor.download_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m block_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset.zip\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 83\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://orients-ai-artefacts.s3.eu-north-1.amazonaws.com/selection-tasks/landc02/dataset.zip\"\n",
    "image_processor = ImageProcessor(dataset_url=dataset_url)\n",
    "\n",
    "# Load the dataset\n",
    "_ = image_processor.load_dataset()\n",
    "image_processor.process_images()\n",
    "similar_pairs = image_processor.compare_sift_features(ratio_thresh=0.75)\n",
    "print(\"Similar pairs of images:\")\n",
    "for img1, img2, num_matches in similar_pairs:\n",
    "\tprint(f\"Image 1: {img1}, Image 2: {img2}, Matches: {num_matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ebd1d-e1d4-4687-a482-86dd13ec5445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
